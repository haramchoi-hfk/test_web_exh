---
title: '[번역] ChatGPT는 웹의 흐릿한 JPEG이다'
date: '2023-04-21'
lastUpdate: '2023-04-21'
summary: '이 글은 2023년 2월 9일 The New Yorker에 게재된 Ted Chiang의 사설 ｢ChatGPT Is a Blurry JPEG of the Web｣을 한글로 번역한 것이다. 2013년, 독일의 한 건설회사는 자신들이 사용하는 제록스(Xerox) 복사기의 이상한 점을 발견한다. 건물의 평면도를 복사할 때마다 복사본이 원본과 미묘하지만 분명하게 달랐던 것이다. 원본 건물에 있는 세 개의 방은...'
keywords: 'ChatGPT, AI, Machine Learning, ML, compression, art, ted chiang, 챗gpt, 인공지능, 머신러닝, 압축, 예술, 테드 창'
---
<div>


<small>　- 이 글은 2023년 2월 9일 The New Yorker에 게재된 Ted Chiang의 사설 <u>[｢ChatGPT Is a Blurry JPEG of the Web｣](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web)</u>을 한글로 번역한 것이다.</small>
<br><br>

　2013년, 독일의 한 건설회사는 자신들이 사용하는 제록스(Xerox) 복사기의 이상한 점을 발견한다. 건물의 평면도를 복사할 때마다 복사본이 원본과 미묘하지만 분명하게 달랐던 것이다. 원본 건물에 있는 세 개의 방은 각각 그것의 면적을 지정하는 직사각형과 함께 표기되어 있었다. 방들은 각각 14.13, 21.11, 그리고 17.42 제곱미터였다. 하지만 복사본에는 모든 방이 14.13 제곱미터로 표기되어 있었다. 회사는 이 얼핏 이해하기 어려운 결과를 분석하기 위해 다비드 크리셀 (David Kriesel)이라는 컴퓨터 공학자에게 연락했다. 그들이 컴퓨터 공학자를 찾아 나선 것은 그 당시 최신 제록스 복사기가 물리적인  제로그래픽 프로세스(xerographic process)라는, 1960년대 당시에 대중화된 기술을 사용하지 않았기 때문이다. 이 기술 대신 그 복사기는 문서를 디지털의 형태로 스캔하여 얻은 이미지를 인쇄하는 방식으로 작동했다. 거의 모든 디지털 이미지 파일이 저장 공간을 절약하기 위해 압축된다는 사실을 함께 고려해 본다면, 위 수수께끼의 실마리는 쉽게 드러날 것이다.

　파일 압축에는 두 가지의 과정이 필요하다. 첫째는 인코딩으로, 이 과정에서 파일이 더 작은 포맷으로 변환된다. 둘째는 디코딩으로, 여기서는 앞선 과정을 거꾸로 수행한다. 만일 두 번째 과정을 통해 복구된 파일이 원본과 동일하다면, 우리는 그것을 무손실 압축이라고 부른다. 어떠한 정보도 손실되지 않은 것이다. 반면에, 복구된 파일이 원본의 근사치에 불과하다면 그것은 손실 압축이라 불린다. 무손실 압축은 주로 텍스트 파일과 컴퓨터 프로그램에 사용되는데, 이는 이들 영역에서는 단 하나의 잘못된 글자조차도 치명적인 문제를 일으킬 수 있기 때문이다. 손실 압축은 주로 사진, 오디오, 그리고 비디오에 사용되는데, 이는 이들에게 완벽한 정확도가 요구되지 않기 때문이다. 우리는 대체로 사진, 음악, 혹은 영화가 완벽하게 재생되지 않더라도 알아차리지 못한다. 오직 압축률이 매우 높은 경우에만 우리는 그 손실을 인지하게 된다. 이러한 경우에 우리는 압축 아티팩트(compression artifacts) 라고 하는 현상을 보게 된다(역주: 일상 용어에서 화질 저하 혹은 디지털 풍화/열화라고 한다). 작은 JPEG와 MPEG 파일의 흐릿함, 낮은 비트레이트의 MP3에서 듣게 되는 작은 소리들이 이러한 아티팩트이다.

　제록스 복사기는 JBIG2라고 알려진, 흑백 이미지에 사용하도록 디자인된 손실 압축 포맷을 사용한다. 이 복사기들은 내부 저장 공간을 절약하기 위해 이미지 내부에 유사해 보이는 영역들을 식별하여 그 영역들을 하나의 영역으로 저장한다. 그 이후 재구축 과정에서, 복사기는 저장된 하나의 영역을 모든 유사한 영역의 재구축을 위해 사용한다. 결국 그 복사기는 방들의 면적을 표기한 영역들이 유사하여 오직 하나의 (14.13) 표기만을 저장하면 된다고 판단/저장했으며, 그 저장된 표기를 재사용하여 평면도를 인쇄한 것이다.

　제록스 복사기가 무손실이 아닌 손실 압축 방식을 사용하는 것은 그 자체로서는 문제가 아니다. 문제는, 그 복사기가 이미지를 손상한 방식이 미묘했던 탓에 그 압축 아티팩트를 곧바로 알아채기 어려웠다는 것이다. 만일 복사기가 그저 뿌옇게 흐려진 이미지를 출력했다면, 누구라도 그 출력물이 잘못된 것이라는 것을 금세 알아차렸을 것이다. 문제의 원인은 그 복사기가 틀렸음에도 불구하고 읽을 수 있는 숫자들을 출력했다는 것이다. 그것이 그 복사본들이 틀리지 않은 것처럼 보이게끔 했다. (제록스는 2014년에 이 이슈를 정정하는 패치를 배포했다)

　OpenAI의 ChatGPT, 그리고 A.I. 연구자들이 대형 언어 모델(large language model)이라고 부르는 프로그램들과 관련하여, 나는 이 제록스 복사기 사건이 오늘날 재고할 가치가 있는 사건이라고 생각한다. 복사기와 대형 언어 모델 사이의 관계는 얼핏 눈에 보이지 않을지도 모르겠다. 하지만 이하와 같은 시나리오를 고려해 보자. 당신이 앞으로 인터넷을 영원히 사용하지 못하게 된다고 상상해보라. 그리고 당신은 이에 대한 대비책으로 인터넷상의 모든 텍스트를 복사/압축하여 개인 서버에 저장하려고 한다. 그러나 안타깝게도 당신의 개인 서버는 요구되는 전체 저장 공간의 단 1퍼센트만을 충족한다. 무손실 압축을 이용해 모든 텍스트를 저장하는 것은 불가능한 것이다. 그리하여 당신은 텍스트의 통계적 규칙성을 식별하여 특수한 포맷으로 그 텍스트를 저장하는 알고리즘을 작성한다. 이 작업에 사용될 수 있는 연산 능력은 사실상 무한하기 때문에, 당신의 알고리즘은 고도로 미묘한 통계적 규칙성까지 식별할 수 있으며, 이를 통해 당신은 당신이 원하는 1/100의 압축률을 달성한다. 

　자, 이제 인터넷을 사용하지 못하는 것이 그렇게까지 끔찍하진 않다. 당신은 필요한 모든 인터넷상의 정보를 서버에 저장했다. 한 가지 문제가 있다면, 이 텍스트들이 고도로 압축된 탓에 정확하게 일치하는 문구를 검색할 수 없다는 것이다. 왜냐하면 손실 압축을 통해 저장된 텍스트는 더이상 이전의 텍스트와 동일하지 않기 때문이다. 당신은 이 문제를 해결하기 위해 인터페이스를 만든다. 그 인터페이스에 당신은 질문 형태의 쿼리를 입력하고, 서버에 저장된 정보의 요점을 기반으로 작성된 답변을 받는다. 

　내가 여기 서술한 내용은 ChatGPT 혹은 대부분의 대형 언어 모델과 매우 유사하다. ChatGPT를 웹상에 있는 모든 텍스트를 흐릿하게 처리한 JPEG라고 생각해 보자. 마치 JPEG가 고해상도의 이미지가 갖고 있는 정보를 대체로 잘 유지하고 있듯이, ChatGPT 또한 웹상의 정보를 대체로 잘 간직하고 있다. 하지만 당신은 정확한 비트시퀀스 (sequence of bits)를 검색하지는 못한다. 당신이 그것으로부터 얻을 수 있는 것은 다만 근사치에 불과하다. ChatGPT의 경우, 이 근사치가 문법적인 텍스트의 형태로 제공되며, ChatGPT는 이를 탁월하게 수행하기 때문에 그 결과들은 대체로 우리가 납득할 만한 것들이다. 그러니까, 우리는 여전히 흐릿한 JPEG를 바라보고 있지만, 그것은 사진 전체의 선명도를 떨어뜨리지 않는 방식의 흐릿함이다.

　이 손실 압축 비유는 웹상의 정보를 재포장하는 ChatGPT의 기능을 그저 다른 방식으로 설명하기만 하는 것이 아니다. 이를 통해 우리는 ChatGPT와 같은 대형 언어 모델에서 발생하기 쉬운 [“환각” (hallucination)](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)) 혹은 사실에 입각한 질문에 대한 터무니없는 대답을 이해할 수 있다. 이 환각은 압축 아티팩트인데, (제록스 복사기가 출력한 잘못된 표기들과 같이) 이들은 다분히 그럴듯하게 보여 이들을 식별하기 위해서는 원본과 대조하는 과정이 요구된다. 이 경우에 원본은 웹상의 정보, 혹은 세계에 대한 우리들 자신의 지식일 것이다. 이러한 방식으로 생각해 보면, 환각은 전혀 놀라운 일이 아니다. 압축을 위한 알고리즘이 원본의 99%를 폐기하도록 설계되었다면, 이후에 재생산되는 생성물의 대부분은 완전히 조작되리라 예측하는 것이 타당하다.

　이 비유는 우리가 손실 압축 알고리즘이 사용하는 일반적인 기법이 [보간(補間, interpolation)](https://ko.wikipedia.org/wiki/%EB%B3%B4%EA%B0%84%EB%B2%95), 다시 말해 거리를 두고 떨어진 서로 다른 둘 사이의 값을 그 간격의 양쪽 끝에 있는 값을 바탕으로 추정하는 것이라는 점을 기억하면 더욱 잘 이해될 것이다. 어떤 이미지를 보여주는 프로그램이 사진 한 장을 보여주는 과정에서 누락된 픽셀을 재생시켜야 한다면, 그 프로그램은 누락된 픽셀 인근에 있는 픽셀들의 값을 참조하여 그 평균을 계산한다. 예를 들어 ChatGPT에게 건조기에서 양말을 잃어버린 상황을 독립선언서 스타일로 서술하라고 해보자. 그 후에 그것이 수행하는 작업은 다음과 같다: 우선 ChatGPT는 어휘 공간(lexical space)에 임의의 두 지점을 선택하고, 그 두 지점 사이의 공간에 사용될 수 있는 텍스트를 생성한다. (“… 독립선언서의 문체로 작성된 건조기에서 양말을 잃어버린 상황 … 영어로 출력된 ChatGPT의 답변 예시 …”) ChatGPT는 이러한 형태의 보간에 매우 능숙하며 따라서 사람들은 사진 대신 언어적 단락을 흐리게 처리할 수 있는 도구로서 이를 즐겁게 사용하는 것이다.

　ChatGPT와 같은 대형 언어 모델이 종종 인공 지능의 최첨단으로 찬사를 받는다는 점을 감안할 때, 이를 손실 텍스트 압축 알고리즘이라고 설명하는 것은 이를 무시하거나 적어도 기를 꺾는 것처럼 들릴 수도 있다. 나는 이 관점이 대형 언어 모델을 의인화하는 경향에 유용한 시사점을 제시한다고 생각하지만, 이 압축 비유에는 고려할 만한 가치가 있는 또 다른 면이 있다. 마커스 허터(Marcus Hutter)라는 이름의 인공지능 연구자는 2006년부터 ‘인간 지식 압축상’(Prize for Compressing Human Knowledge)이라는 상을 만들어 위키피디아의 특정 스냅샷 1기가바이트를 이전 수상자보다 더 작게 무손실 압축하는 사람에게 상금을 지급하고 있다. zip이라는 압축 포맷은 허터가 제시한 1기가바이트 크기의 파일을 약 300메가바이트로 줄일 수 있다. 가장 최근의 시상자는 이를 150메가바이트로 줄였다. 이것은 단순한 연습이 아니다. 허터는 더 나은 텍스트 압축 기술이 인간 수준의 인공 지능을 만드는 데 중요한 역할을 할 것이라고 믿는데, 이는, 부분적으로는, 높은 수준의 압축률을 달성하기 위해서는 그 텍스트를 이해하는 것이 필요하기 때문이다.

　위에서 제시된 압축(compression)과 이해(understanding) 사이의 관계를 이해하기 위해, 수백만 개의 덧셈, 뺄셈, 곱셈, 그리고 나눗셈에 관한 예시가 담긴 텍스트가 있다고 가정해 보자. 물론 어떤 압축 알고리즘이라도 이 텍스트의 크기를 줄일 수 있겠지만, 아마도 그 산술적 원리를 도출해서 계산기 프로그램을 위한 코드를 작성하는 것이 가장 높은 압축률을 달성할 것이다. 계산기를 이용한다면, 우리는 비단 주어진 텍스트 내에 등장하는 예시들뿐 아니라 우리가 앞으로 마주칠 어떤 수학 문제라도 해결할 수 있을 것이다. 이는 위키피디아의 일부분을 압축하는 문제에도 동일하게 적용된다. 질량과 가속도의 곱으로 힘을 도출할 수 있다는 사실을 알고 있는 압축 프로그램은 물리학에 관한 페이지를 압축하는 과정에서 많은 단어를 버릴 수 있는데, 이는 그 프로그램이 차후에 이를 재구축할 수 있기 때문이다. 마찬가지로, 이 압축 프로그램은 수요와 공급에 관해 알고 있는 만큼 경제학에 관한 페이지에서 많은 단어를 버릴 수 있다. 

　대형 언어 모델들은 텍스트의 통계적 규칙성을 식별한다. 웹상의 텍스트들에서 “공급이 낮다”는 문구는 “가격이 상승한다”와 같은 문구와 가까운 곳에 자주 등장한다. 이러한 상관관계를 반영한 챗봇이라면 공급 부족의 영향에 관한 질문을 받았을 때, 가격 상승에 관한 답변을 내놓을 것이다. 만일 어떤 대형 언어 모델이 방대한 양의 경제학 용어들과 그들 간의 상관관계를 알고 있다면, 그래서 다양한 질문들에 그럴듯한 답변을 내놓을 수 있다면, 우리는 과연 그것이 경제학 이론을 이해한다고 말할 수 있을까?

　산술의 예로 돌아가 보자. 만일 우리가 GPT-3(ChatGPT의 기반이 된 대형 언어 모델)에게 한 쌍의 숫자를 서로 더하거나 빼라고 묻는다면, 두 자리 숫자의 경우에는 항상 옳은 답을 내어놓는다. 하지만 숫자가 커질수록 답의 정확도는 크게 떨어지며, 숫자가 다섯 자리 일 때는 10%까지 떨어진다. GPT-3가 내놓은 정답 중 대부분은 웹상에 존재하지 않는다. (가령, “245+821”을 포함하는 웹페이지는 많지 않다) 따라서 이는 단순한 기억과는 무관하다. 그러나 방대한 양의 정보를 집어넣었음에도 불구하고 그것이 산술적 원리를 도출해 내지 못했다는 것 또한 사실이다. GPT-3의 오답을 분석한 결과, GPT-3가 산술 과정에서 “1”의 자리 이동을 고려하지 않는다는 것이 확인되었다(역주: 이는 십진법의 덧셈 과정에서 9를 초과할 때 왼쪽의 수를 1 증가시키는 것을 의미). 웹에는 분명 “1”의 자리 이동에 관한 설명이 있지만, GPT-3는 이 설명을 산술 과정에서 고려할 능력이 없는 것이다. 산술 예제에 대한 GPT-3의 통계적 분석은 실제에 대한 피상적인 근사치를 생산할 수는 있지만, 그 이상은 수행할 수 없다. 

　GPT-3가 초등학교에서 가르치는 주제에 관해 오답을 내놓는다는 사실을 감안할 때, 이것이 종종 대학교 수준의 에세이를 잘 써내는 것은 어떻게 설명할 수 있을까? 대형 언어 모델들은 종종 환각을 일으키지만, 명료한 상태에서는 마치 경제 이론과 같은 주제를 실제로 이해하는 것처럼 보인다. 어쩌면 산술은 대형 언어 모델들이 적합하지 않은 하나의 특별한 경우일지도 모르겠다. 그러나, 덧셈과 뺄셈을 제외한다면, 텍스트의 통계적 규칙성이 실제 세계에 대한 진정한 지식과 일치할 수 있는 걸까?

　내 생각에 대답은 간단하다. ChatGPT가 무손실 압축 알고리즘이라고 상상해 보자. 이 경우에 ChatGPT는 항상 관련된 웹페이지의 내용을 그대로 인용하여 질문에 답할 것이다. 그래서 아마도 우리는 이 소프트웨어를 기존 검색 엔진에 비해 약간 개선된 수준의 것으로 간주하고 크게 감명받지 못했을 것이다. ChatGPT는 웹상의 문장들을 그대로 인용하는 것이 아니라 바꾸어서 답변하는데, 이것이 마치 학생이 읽은 자료를 그대로 반복하지 않고 자신만의 어휘를 사용하여 생각을 표현하는 것처럼 보이게끔 한다. 그래서 ChatGPT가 그 자료를 이해한다는 착시가 발생하는 것이다. 인간 학생의 경우에 기계적 암기는 진정한 학습으로 간주하지 않는다. 따라서 ChatGPT가 웹페이지의 자료를 그대로 인용하지 못한다는 점이 우리로 하여금 그것이 무언가를 학습했다고 생각하게 하는 것이다. 일련의 단어들과 관련한 문제에 관한 한, 우리는 손실 압축이 무손실 압축보다 더 똑똑하다고 여기는 것이다. 

　대형 언어 모델의 용도로서 많은 제안들이 있어왔다. 이것들을 흐릿한 JPEG로서 생각한다면, 우리는 이들의 적합한 용도를 평가할 수 있는 방법을 알 수 있다. 몇 가지 시나리오를 고려해보자.

　대형 언어 모델이 전통적인 검색 엔진을 대체할 수 있는가? 이들을 신뢰하기 위해서 우리는 이들이 프로파간다와 음모론으로 학습되지 않았다는 것, 즉 이 JPEG가 웹의 올바른 부분을 캡처하고 있다는 것을 알수 있어야 한다. 그러나 대형 언어 모델이 우리가 원하는 정보만을 포함하고 있다고 해도, 흐릿함의 문제는 여전히 존재한다. 물론 수용 가능한 흐릿함도 있다. 그것은 그 정보의 문장을 재구성하는 것이다(re-stating of information in different words). 그러나 노골적인 조작의 흐릿함 또한 존재하며, 이는 우리가 사실을 찾고자 하는 경우에는 용납될 수 없다. 수용 가능한 흐릿함은 유지하면서도 용납 불가능한 흐릿함을 없애는 것이 기술적으로 가능한지는 명확하지 않지만, 나는 이것이 가까운 시일 내에 가능해질 것으로 기대한다.

　설령 대형 언어 모델이 날조와 조작에 관여하지 못하도록 제한할 수 있다고 해도, 우리는 웹 콘텐츠를 생성하는 데 이를 사용해야 할까? 이는 오직 우리가 이미 웹에 존재하는 정보를 재포장하고자 할 때만 의미가 있을 것이다. 이러한 업무를 수행하는 회사들은 이미 존재한다. 이러한 회사들은 보통 content mill(역주: 혹은 콘텐츠 팜farm)이라고 불린다. 대형 언어 모델의 흐릿함은 이러한 회사에 저작권 위반을 피하는 방편으로써 유용할 수 있다. 하지만 일반적으로 콘텐츠 밀 회사에 유용한 것은 정보를 찾는 사람들에게 유용하지 않다. 이러한 종류의 재포장은 현재 우리가 온라인에서 원하는 것을 찾는 것을 더욱 어렵게 만든다. 웹상에 대형 언어 모델에 의해 생성된 텍스트가 더욱 많아질수록, 웹은 그 자체로서 더 흐릿해진다. 

　OpenAI가 곧 출시할 ChatGPT의 후속 버전인 GPT-4에 대한 정보는 알려진 것이 거의 없다. 하지만 한 가지 예측을 해보자면, GPT-4를 학습시키는 데 사용되는 방대한 양의 텍스트를 수집할 때 OpenAI의 개발자들은 ChatGPT나 다른 대규모 언어 모델에서 생성된 자료를 제외하기 위해 모든 노력을 기울였을 것이다. 만약 이것이 사실로 밝혀진다면, 이는 대형 언어 모델과 손실 압축 사이의 비유가 유용하다는 것을 의도치 않게 확인시켜주는 역할을 하게 될 것이다. JPEG를 반복적으로 저장하면 매번 더 많은 정보가 손실되기 때문에 더 많은 압축 아티팩트가 발생하게 된다. 이는 옛날에 복사본의 복사본을 반복적으로 만들던 것과도 같다. 이미지 품질은 더 낮아지기만 할 뿐이다.

　실제로 회사가 생성된 텍스트를 다음 세대 모델의 학습 데이터로 사용하려는 의지의 여부는 그 텍스트를 생성한 대형 언어 모델의 품질을 측정하는 기준으로서 유용할 것이다. 만약 ChatGPT의 생성물이 GPT-4의 학습에 사용할만큼 좋지 않다면, 이는 그 생성물이 우리에게도 좋지 않다는 신호가 될 것이다. 반대로 어떤 모델이 생성한 텍스트가 새로운 모델을 학습하는데 사용할 수 있을만큼 좋다면, 우리는 그 텍스트의 품질을 신뢰해도 될 것이다(이러한 결과를 얻으려면 이 모델들을 구축하는데 사용된 기술에 큰 혁신이 있어야 한다고 추정한다). 이 대형 언어 모델들이 자신들의 학습 자료로 사용되어도 괜찮을만큼 좋은 생성물을 만들어내기 시작한다면, 손실 압축 비유는 더이상 유효하지 않을 것이다. 

　대형 언어 모델들이 인간의 독창적인 글쓰기에 도움을 줄 수 있을까? 이 질문에 답하기 위해서는 이 질문의 의미를 구체적으로 정의할 필요가 있다. 제록스 아트, 혹은 복사 아트(photocopy art) 라고 불리우는 예술 장르가 있는데, 이 장르에서 예술가들은 복사기의 독특한 특성들을 창의적인 도구로 사용한다. 이러한 의미에서 ChatGPT라는 복사기로도 분명 그런 예술을 할 수 있으니, 대답은 “예”이다. 하지만 복사기가 예술 창작에 필수적인 도구가 되었다고 주장하는 사람은 아무도 없다. 대다수의 예술가들은 창작 과정에서 복사기를 사용하지 않으며, 그러한 선택으로 인해 불이익을 받는다고 주장하는 사람도 없다.

　이제 우리가 제록스 아트와 비슷한 어떤 새로운 형태의 글쓰기에 대해서 이야기하는 것이 아니라고 해보자. 이 조건 하에, 픽션이든 논픽션이든, 작가가 독창적인 글을 쓸 때 대형 언어 모델이 생성한 글이 유용한 출발점이 될 수 있을까? 대형 언어 모델이 상용구를 처리해준다면, 작가들은 정말로 창의적인 부분에 더 집중할 수 있을까?

　물론 누구도 모든 작가들을 대변할 수는 없다. 하지만 나는 비독창적인(unoriginal) 작품의 모호한 복사본으로 시작하는 것은 독창적인 작품을 창작하는데 좋지 않다고 주장하고 싶다. 당신이 글 작가라면, 당신은 뭔가 독창적인 것을 쓰기 전에 다량의 비독창적인 글을 쓰게 될 것이다. 그리고 그 비독창적인 작업에 소요된 시간과 노력은 낭비가 아니다. 나는 오히려 바로 그것이 당신이 독창적인 것을 창작할 수 있게끔 해주는 것이라고 생각한다. 올바른 단어를 선택하고 더욱 매끄럽게 문장을 재배열하는 과정은 글에서 의미가 어떻게 전달되는지를 가르쳐준다. 학생들에게 에세이를 쓰게 하는 것은 단순히 자료의 이해도를 테스트하는 것이 아니라, 자신의 생각을 명확하게 표현하는 경험을 제공한다. 만일 학생들이 우리가 예전에 읽었던 것과 같은 에세이를 전혀 쓰지 않는다면, 그들은 우리가 전에 읽어본 적 없는 새로운 종류의 글을 쓸 수 있는 기술을 절대로 습득할 수 없다. 

　학생이 아니라고 해서 대형 언어 모델이 제공하는 템플릿을 사용하는 것이 괜찮다는 것이 아니다. 자신의 생각을 표현하기 위한 노력은 졸업한다고 해서 사라지는 것이 아니라 새로운 글의 초고를 작성할 때마다 계속될 수 있다. 때로는 오직 글을 쓰는 과정에서만 독창적인 아이디어를 발견하기도 한다. 혹자는 대형 언어 모델의 결과물이 인간 작가의 초고와 크게 다르지 않다고 말할 수 있다. 하지만 나는 이것이 다만 피상적인 닮아있음일 뿐이라고 생각한다. 초고라는 것은 명확하게 표현된 비독창적인 아이디어가 아니다. 그것은 제대로 표현되지 않은 독창적인 아이디어이며, 당신의 보이지 않는 불만, 당신이 말하고자 하는 내용과 작성된 초고가 말하는 내용 사이의 거리에 대한 당신의 인식을 동반한다. 이것이 바로 글을 탈고하고 수정하는 과정에서 당신을 이끄는 것이며, 인공지능이 생성한 텍스트로 글쓰기를 시작할 때 결여되는 것이다.

　글쓰기는 마술이나 신화는 아니지만, 이미 존재하는 문서를 신뢰할 수 없는 복사기에 넣고 프린트 버튼을 누르는 것 이상의 과정이 필요하다. 미래에는 세상에 대한 자신의 경험만을 바탕으로 좋은 산문을 쓸 수 있는 인공지능을 만들 수 있을지도 모른다. 우리가 그것을 달성하는 날은 참으로 중대한 순간이 될 것이지만, 아직 그 날은 예측의 지평선 너머에 있다. 그 날이 오기 전까지, 단순히 웹을 재구성하는 것에 무슨 의미가 있냐고 물어볼 수도 있다. 만일 우리가 영원히 인터넷에 접속할 수 없는 상황이 온다면, 그래서 웹의 복사본을 개인 서버에 저장해야 한다면, 날조와 왜곡으로부터 안전하다는 것을 전제로 ChatGPT와 같은 대형 언어 모델이 좋은 해결책이 될 수 있다. 그러나 그러한 상황은 오지 않는다. 그렇다면, 우리가 원본을 갖고 있는 상황에서 흐릿한 JPEG이 얼마나 유용할 수 있을까?

</div>